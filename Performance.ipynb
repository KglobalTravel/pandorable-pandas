{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "\n",
    "\n",
    "*Avoiding slow code*\n",
    "\n",
    "With pandas, you'll get the most bang for your performance-buck by avoiding antipatterns. Once you've done that there are additional options like using Numba or Cython if you really need to optimize a piece of code, but that's more work typically.\n",
    "\n",
    "This notebook will walk through several common miskates, and show more performant ways of achieving the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistake 1: Using pandas\n",
    "\n",
    "pandas isn't always the right choice. If you're dealing with non-tabular data, or lots of linear algebra, you might be better off using something else like Python lists / dicts / sets, or raw NumPy arrays.\n",
    "\n",
    "## Mistake 2: Using object dtype\n",
    "\n",
    "Jake VanderPlas has a [great article](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/) on why Python is slow for many of the things we care about as analysts / scientists. One reason is the overhead that comes from  using python objects for integers, floats, etc. relative to their native versions in languages like C.\n",
    "\n",
    "As a small demonstration, we'll make two series, one with python integers, and one with NumPy's int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two series of range(10000), different dtypes\n",
    "s1 = pd.Series(range(10000), dtype=object)\n",
    "s2 = pd.Series(range(10000), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a simple operation on them, like taking the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit s1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit s2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy can process the specialized int64 dtype array faster than the python object version, even though they're equal. Part of this comes from the different algorithms (the NumPy version would overflow with very large integers), and part comes from the Python version having to repeated unbox the actual integer from the Python object, and re-box it for the result.\n",
    "\n",
    "Typically you would never expecitly pass in dtype=object there, but occasionally object dtypes slip into pandas\n",
    "\n",
    "* Reading messy Excel Files / CSV files\n",
    "\n",
    "  These file types either don't have or don't enforce types. pandas has to infer dtypes, which doesn't always go as expected\n",
    "\n",
    "* \"Exotic\" data types like Dates, Times, Decimals\n",
    "\n",
    "    Pandas has implemented a specialized verion of datetime.datime, and datetime.timedelta, but not datetime.date, datetime.time, Decimal, etc. Depending on your application, you might be able to treat dates as datetimess, at midnight.\n",
    "\n",
    "As discussed in the [pandas documentation](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes), pandas uses NumPy's data types. Recent versions include more *extension types*, which are non-NumPy dtypes inside a Series or a DataFrame. Right now the most popular are\n",
    "\n",
    "* Datetimes with Timezones\n",
    "* Categorical\n",
    "* StringDtype\n",
    "* Nullable Integer\n",
    "* Nullable Boolean\n",
    "\n",
    "Previously, pandas couldn't natively store an array of integers with some missing values, since we used `np.nan` as a missing value indicator. `np.nan` is a float, and an array of some integers and some floats is just cast to an array of floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, None, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have explicitly requested `dtype=object` to keep it from being cast to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, None, 2], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as we know, object-dtype is slow. It's better to use pandas nullable integer dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, None, 2], dtype=pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([None] + list(range(10000)), dtype=object)\n",
    "%timeit a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([None] + list(range(10000)), dtype=pd.Int64Dtype())\n",
    "%timeit b.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have some messy data in-memory (in a Python list, say) that you wish to convert, use one of pandas' parsers like\n",
    "\n",
    "- `pd.to_numeric`\n",
    "- `pd.to_datetime`\n",
    "- `pd.to_timedelta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoricals\n",
    "\n",
    "pandas has a [Categorical Data Type](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html) that represents data coming from a speficify, and typically *fixed* set of values. It's data model includes two components:\n",
    "\n",
    "1. `categories`: An Index storing the set of valid values.\n",
    "2. `ordered`: A boolean flag indicating whether there's an ordering between the values.\n",
    "\n",
    "If you try to set a value that's not contained in the `categories`, you'll see an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Categorical(['good', 'better', 'good', 'best'],\n",
    "                   categories=['good', 'better', 'best'],\n",
    "                   ordered=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the primary intent of categoricals was to model data with a fixed set of allowed values, their implementation suggests another use: saving memory and improving performance.\n",
    "\n",
    "When you make a Categorical, pandas will *factorize* the values. This creates a mapping between the original value and an integer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two things:\n",
    "\n",
    "1. The value `\"good\"` is associated with code `0`, the first element in `.categories`.\n",
    "2. The codes are stored as `int8`.\n",
    "\n",
    "When you have many repeated values, whose regular representation are larger than int8, then storing the data as Categorical can have some performance benefits.\n",
    "\n",
    "To demonstrate this, let's suppose you had a table with every adult resident of the United States (about 321,000,000 rows) where one column stores the state abbreviation as a string.\n",
    "\n",
    "Just storing this as an object-dtype array would cost the size of the 2-character string times the 321,000,000 occurances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "population = 321_000_000\n",
    "bytes_per = sys.getsizeof(\"AL\")  # two characters per state\n",
    "print(\"{:,d} MB\".format((population * bytes_per // 1_000_000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or about 16GB. How many MB would you need to store the same as a Categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/performance_categorical.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when there are many repeated values the savings can be dramatic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Just like with NumPy, *vectorization* is key to getting good performance out of pandas.\n",
    "The short definition is \"don't do for loops\", the longer definition is \"let NumPy do the for loop in C\".\n",
    "\n",
    "As an example, let's grab some data on airports locations. We'll compote the distances between pairs of airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\n",
    "    \"https://vega.github.io/vega-datasets/data/airports.csv\",\n",
    "    index_col=\"iata\",\n",
    "    nrows=500,\n",
    ")\n",
    "airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block is a bit of pandas magic to build a DataFrame with each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"longitude\", \"latitude\"]\n",
    "idx = pd.MultiIndex.from_product([airports.index, airports.index],\n",
    "                                 names=['orig', 'dest'])\n",
    "subset = idx.get_level_values(0) > idx.get_level_values(1)\n",
    "\n",
    "pairs = pd.concat([\n",
    "    airports[columns]\n",
    "        .add_suffix('_orig')\n",
    "        .reindex(idx, level='orig'),\n",
    "    airports[columns]\n",
    "        .add_suffix('_dest')\n",
    "        .reindex(idx, level='dest')\n",
    "    ], axis=\"columns\"\n",
    ")[subset]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def gcd_py(lat1, lng1, lat2, lng2):\n",
    "    '''\n",
    "    Calculate great circle distance between two points.\n",
    "    https://www.johndcook.com/blog/python_longitude_latitude/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1, lng1, lat2, lng2: float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance:\n",
    "      distance from ``(lat1, lng1)`` to ``(lat2, lng2)`` in kilometers.\n",
    "    '''\n",
    "    degrees_to_radians = math.pi / 180.0\n",
    "    ϕ1 = (90 - lat1) * degrees_to_radians\n",
    "    ϕ2 = (90 - lat2) * degrees_to_radians\n",
    "\n",
    "    θ1 = lng1 * degrees_to_radians\n",
    "    θ2 = lng2 * degrees_to_radians\n",
    "\n",
    "    cos = (math.sin(ϕ1) * math.sin(ϕ2) * math.cos(θ1 - θ2) +\n",
    "           math.cos(ϕ1) * math.cos(ϕ2))\n",
    "    # round to avoid precision issues on identical points causing ValueErrors\n",
    "    cos = round(cos, 8)\n",
    "    arc = math.acos(cos)\n",
    "    return arc * 6373  # radius of earth, in kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcd_vec(lat1, lng1, lat2, lng2):\n",
    "    '''\n",
    "    Calculate great circle distance.\n",
    "    https://www.johndcook.com/blog/python_longitude_latitude/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1, lng1, lat2, lng2: float or array of float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance:\n",
    "      distance from ``(lat1, lng1)`` to ``(lat2, lng2)`` in kilometers.\n",
    "    '''\n",
    "    ϕ1 = np.deg2rad(90 - lat1)\n",
    "    ϕ2 = np.deg2rad(90 - lat2)\n",
    "\n",
    "    θ1 = np.deg2rad(lng1)\n",
    "    θ2 = np.deg2rad(lng2)\n",
    "\n",
    "    cos = (np.sin(ϕ1) * np.sin(ϕ2) * np.cos(θ1 - θ2) +\n",
    "           np.cos(ϕ1) * np.cos(ϕ2))\n",
    "    # round to avoid precision issues on identical points causing warnings\n",
    "    cos = np.round(cos, 8)\n",
    "    arc = np.arccos(cos)\n",
    "    return arc * 6373 # radius of earth, in kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# gcd_py with DataFrame.apply\n",
    "r = pairs.apply(\n",
    "    lambda x: gcd_py(x['latitude_orig'],\n",
    "                     x['longitude_orig'],\n",
    "                     x['latitude_dest'],\n",
    "                     x['longitude_dest']),\n",
    "                axis=\"columns\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# gcd_py with manual iteration\n",
    "_ = pd.Series([gcd_py(*x) for x in pairs.itertuples(index=False)],\n",
    "              index=pairs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# gcd_vec\n",
    "r = gcd_vec(pairs['latitude_orig'], pairs['longitude_orig'],\n",
    "            pairs['latitude_dest'], pairs['longitude_dest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more, consult these pages from pandas' documentation:\n",
    "\n",
    "* Enhancing performance: https://pandas.pydata.org/docs/user_guide/enhancingperf.html\n",
    "* Scaling to larger datasets: https://pandas.pydata.org/docs/user_guide/scale.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
